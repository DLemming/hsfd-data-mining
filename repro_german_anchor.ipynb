{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e32cb1f",
   "metadata": {},
   "source": [
    "# Reproduce the papers results on the German Credit Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7431be",
   "metadata": {},
   "source": [
    "### 1. Init & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1804476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train set: 700\n",
      "Length test set: 300\n"
     ]
    }
   ],
   "source": [
    "from anchor import anchor_tabular\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "\n",
    "def load_ds(name):\n",
    "    assert name in [\"german\", \"adult\"]\n",
    "\n",
    "    # Load train set\n",
    "    title = \"scripts/datasets/train_set_\"+name+\"_strat.p\"\n",
    "    train = open(title,\"rb\")\n",
    "    train_set: pd.DataFrame = pickle.load(train)\n",
    "\n",
    "    title = \"scripts/datasets/train_label_\"+name+\"_strat.p\"\n",
    "    train_l = open(title,\"rb\")\n",
    "    train_label: pd.DataFrame = pickle.load(train_l)\n",
    "\n",
    "    # Load Test set\n",
    "    title = \"scripts/datasets/test_set_\" + name + \"_strat.p\"\n",
    "    test = open(title, \"rb\")\n",
    "    test_set: pd.DataFrame = pickle.load(test)\n",
    "\n",
    "    title = \"scripts/datasets/test_label_\" + name + \"_strat.p\"\n",
    "    test_l = open(title, \"rb\")\n",
    "    test_label: pd.DataFrame = pickle.load(test_l)\n",
    "\n",
    "    # Reset indices\n",
    "    train_set = train_set.reset_index(drop=True)\n",
    "    train_label = train_label.reset_index(drop=True)\n",
    "    test_set = test_set.reset_index(drop=True)\n",
    "    test_label = test_label.reset_index(drop=True)\n",
    "\n",
    "    # Convert object columns to int\n",
    "    train_set = train_set.astype(int)\n",
    "    test_set = test_set.astype(int)\n",
    "\n",
    "    return train_set, train_label, test_set, test_label\n",
    "\n",
    "train_set, train_label, test_set, test_label = load_ds(\"german\")\n",
    "\n",
    "print(\"Length train set:\", len(train_set))\n",
    "print(\"Length test set:\", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde023b7",
   "metadata": {},
   "source": [
    "### 2. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f8dfb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model: str, ds: str):\n",
    "    assert model in [\"catboost\", \"lg\", \"xgb\"]\n",
    "    assert ds in [\"adult\", \"german\"]\n",
    "\n",
    "    path = f\"scripts/results/trained_{model}_{ds}.p\"\n",
    "    path_opened = open(path,\"rb\")\n",
    "\n",
    "    if model == \"lg\":\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        model: LogisticRegression = pickle.load(path_opened)\n",
    "    elif model == \"xgb\":\n",
    "        from xgboost import XGBClassifier\n",
    "        model: XGBClassifier = pickle.load(path_opened)\n",
    "    elif model == \"catboost\":\n",
    "        from catboost import CatBoostClassifier\n",
    "        model: CatBoostClassifier = pickle.load(path_opened)\n",
    "\n",
    "    if model is None:\n",
    "        raise Exception()\n",
    "    return model\n",
    "\n",
    "def load_explainer(train_set, train_label):\n",
    "    return anchor_tabular.AnchorTabularExplainer(\n",
    "        class_names=train_label.unique(),\n",
    "        feature_names=train_set.columns,\n",
    "        train_data=train_set.values\n",
    "    )\n",
    "\n",
    "lg = load_model(\"lg\", \"german\")\n",
    "xgb = load_model(\"xgb\", \"german\")\n",
    "cat = load_model(\"catboost\", \"german\")\n",
    "\n",
    "explainer: anchor_tabular.AnchorTabularExplainer = load_explainer(train_set, train_label)\n",
    "\n",
    "def xgb_fn(X):\n",
    "    return xgb.predict(pd.DataFrame(X, columns=test_set.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6b5ea",
   "metadata": {},
   "source": [
    "### 3. Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47ff151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9233333333333333\n",
      "LogReg Accuracy:  0.7166666666666667\n",
      "CatBoost Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict\n",
    "lg_preds  = lg.predict(test_set)\n",
    "xgb_preds = xgb_fn(test_set)\n",
    "cat_preds = cat.predict(test_set)\n",
    "\n",
    "# Accuracy\n",
    "lg_acc  = accuracy_score(test_label, lg_preds)\n",
    "xgb_acc = accuracy_score(test_label, xgb_preds)\n",
    "cat_acc = accuracy_score(test_label, cat_preds)\n",
    "\n",
    "print(\"XGBoost Accuracy:\", xgb_acc)\n",
    "print(\"LogReg Accuracy: \", lg_acc)\n",
    "print(\"CatBoost Accuracy:\", cat_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc8510",
   "metadata": {},
   "source": [
    "### 4a. Calculate Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c13b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def conv_rule_to_pandas_query(rule):\n",
    "    \"\"\"\n",
    "    Converts Anchor rules (list of strings) into a valid pandas .query() expression.\n",
    "    Supports compound range rules like '3.00 < occupation <= 5.00'.\n",
    "    \"\"\"\n",
    "    query_parts = []\n",
    "    \n",
    "    for cond in rule:\n",
    "        # Match compound ranges like '3.00 < occupation <= 5.00'\n",
    "        match = re.match(r\"([\\d\\.]+)\\s*<\\s*(.+)\\s*<=\\s*([\\d\\.]+)\", cond)\n",
    "        if match:\n",
    "            low, col, high = match.groups()\n",
    "            col = col.strip()\n",
    "            expr = f\"({float(low)} < `{col}` <= {float(high)})\"\n",
    "            query_parts.append(expr)\n",
    "            continue\n",
    "        \n",
    "        # Match simple binary comparisons\n",
    "        match = re.match(r\"(.+?)\\s*(<=|>=|<|>|==)\\s*([\\d\\.]+)\", cond)\n",
    "        if match:\n",
    "            col, op, val = match.groups()\n",
    "            col = col.strip()\n",
    "            expr = f\"(`{col}` {op} {float(val)})\"\n",
    "            query_parts.append(expr)\n",
    "            continue\n",
    "\n",
    "        raise ValueError(f\"Unsupported condition format: {cond}\")\n",
    "    \n",
    "    return \" & \".join(query_parts)\n",
    "\n",
    "def calculate_fidelity(model_fn, explainer, dataset, tresh=0.95, num_samples=100):\n",
    "    fidelity_scores = []\n",
    "    sampled_count = 0\n",
    "\n",
    "    random_indices = np.random.permutation(len(dataset))  # Randomly shuffle indices\n",
    "\n",
    "    while len(fidelity_scores) < num_samples:  # Continue until we have num_samples valid instances\n",
    "        # Get a new instance and its true label\n",
    "        i = random_indices[sampled_count]\n",
    "        x = dataset.iloc[[i]]\n",
    "        y_true = model_fn(x).item()  # model prediction for the instance\n",
    "        sampled_count += 1\n",
    "\n",
    "        # Explain the instance with Anchor\n",
    "        exp = explainer.explain_instance(x.values, classifier_fn=model_fn, threshold=tresh)\n",
    "        rule = exp.names()  # e.g., [\"age > 30\", \"capital-gain <= 0\"]\n",
    "\n",
    "        if not rule:\n",
    "            continue  # Skip if no rule found\n",
    "\n",
    "        # Convert the Anchor rule to a pandas query expression\n",
    "        query_str = conv_rule_to_pandas_query(rule)\n",
    "\n",
    "        # Check how many of the covered instances match the model's original prediction\n",
    "        covered = dataset.query(query_str)\n",
    "        pred_match = model_fn(covered) == y_true\n",
    "        fidelity = pred_match.mean() if len(covered) > 0 else 0\n",
    "\n",
    "        fidelity_scores.append(fidelity)\n",
    "\n",
    "    return np.mean(fidelity_scores)\n",
    "\n",
    "\n",
    "thresh = 0.4 # default: 0.95\n",
    "num_samples = 15\n",
    "\n",
    "rounds = 5\n",
    "\n",
    "fidelity_lg, fidelity_xgb, fidelity_cat = 0,0,0\n",
    "for _ in tqdm(range(rounds), desc=\"Calculating fidelity\"):\n",
    "    fid_lg_current = calculate_fidelity(lg.predict, explainer, test_set, tresh=thresh, num_samples=num_samples)\n",
    "    fid_xgb_current = calculate_fidelity(xgb_fn, explainer, test_set, tresh=thresh, num_samples=num_samples)\n",
    "    fid_cat_current = calculate_fidelity(cat.predict, explainer, test_set, tresh=thresh, num_samples=num_samples)\n",
    "\n",
    "    fidelity_lg += fid_lg_current / float(rounds)\n",
    "    fidelity_xgb += fid_xgb_current / float(rounds)\n",
    "    fidelity_cat += fid_cat_current / float(rounds)\n",
    "\n",
    "print(\"\\nFidelity results:\")\n",
    "print(f\"LG:\\t{fidelity_lg:.3f}\")\n",
    "print(f\"XGB:\\t{fidelity_xgb:.3f}\")\n",
    "print(f\"CAT:\\t{fidelity_cat:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6e52e",
   "metadata": {},
   "source": [
    "### 5. Calculate Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b87884aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating stability...:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating stability...: 100%|██████████| 5/5 [00:30<00:00,  6.03s/it]\n",
      "Calculating stability...: 100%|██████████| 5/5 [00:29<00:00,  5.96s/it]\n",
      "Calculating stability...: 100%|██████████| 5/5 [00:29<00:00,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LG Stability: 1.0710900227428695\n",
      "XGB Stability: 1.125003788507453\n",
      "CAT Stability: 1.1514746079361342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def jaccard_distance(exp_x: set, exp_x_neigh: set, debug):\n",
    "    \"\"\"Distance between two explanations.\"\"\"\n",
    "    union = exp_x | exp_x_neigh\n",
    "    if not union:\n",
    "        return 0.0  # If both are empty, treat as identical\n",
    "    jacc = 1 - len(exp_x & exp_x_neigh) / len(union)\n",
    "    if debug:\n",
    "        print(\"\\tJacc:\\t\", jacc)\n",
    "    return jacc\n",
    "\n",
    "def hamming_distance(exp_x: set, exp_x_neigh: set, debug=False):\n",
    "    \"\"\"Distance between two explanations using Hamming distance.\"\"\"\n",
    "    # Calculate the symmetric difference between the two sets\n",
    "    diff = exp_x ^ exp_x_neigh  # ^ is symmetric difference\n",
    "    # Normalize the distance by the maximum possible number of differences (size of the union)\n",
    "    max_diff = max(len(exp_x), len(exp_x_neigh))\n",
    "    if max_diff == 0:\n",
    "        return 0.0  # If both are empty, treat as identical\n",
    "    \n",
    "    hamming = len(diff) / max_diff\n",
    "    \n",
    "    if debug:\n",
    "        print(\"\\tHamming:\\t\", hamming)\n",
    "    \n",
    "    return hamming\n",
    "\n",
    "def eucl_distance(x1: np.ndarray, x2: np.ndarray, debug):\n",
    "    \"\"\"Euclidean distance between inputs.\"\"\"\n",
    "    eucl = np.linalg.norm(x1 - x2)\n",
    "    if debug:\n",
    "        print(\"\\tEucl:\\t\", eucl)\n",
    "    return eucl\n",
    "\n",
    "def norm_eucl_distance(x1: np.ndarray, x2: np.ndarray, scaler: MinMaxScaler, debug):\n",
    "    \"\"\"Euclidean distance between inputs, first normalizing features.\"\"\"\n",
    "    \n",
    "    # Normalize the input vectors (x1 and x2)\n",
    "    x1_normalized = scaler.transform([x1])\n",
    "    x2_normalized = scaler.transform([x2])\n",
    "\n",
    "    # Calculate the Euclidean distance between the normalized vectors\n",
    "    eucl_dist = np.linalg.norm(x1_normalized - x2_normalized)\n",
    "\n",
    "    if debug:\n",
    "        print(\"\\tEuc_norm:\\t\", eucl_dist)\n",
    "        \n",
    "    return eucl_dist\n",
    "\n",
    "def calc_lipschitz(exp_x, exp_xp, x, xp, debug, sim, scaler=None):\n",
    "    if sim == \"jaccard\":\n",
    "        exp_dist = jaccard_distance(exp_x, exp_xp, debug)\n",
    "    else:\n",
    "        exp_dist = hamming_distance(exp_x, exp_xp, debug)\n",
    "\n",
    "    if scaler is not None:\n",
    "        input_dist = norm_eucl_distance(x, xp, scaler, debug)\n",
    "    else:\n",
    "        input_dist = eucl_distance(x, xp, debug)\n",
    "\n",
    "    lip = exp_dist/input_dist\n",
    "    if debug:\n",
    "        print(\"\\tLip:\\t\", lip)\n",
    "    return lip\n",
    "\n",
    "def generate_perturbation_neighborhood(x: pd.Series, dataset: pd.DataFrame, num_samples=10, max_perturbation=2):\n",
    "    \"\"\"Generates a synthetic neighborhood around x by applying small perturbations.\"\"\"\n",
    "    neighborhood = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        x_prime = deepcopy(x)\n",
    "\n",
    "        for col in dataset.columns:\n",
    "            # Apply a small perturbation, limiting to max_perturbation in magnitude\n",
    "            perturbation = np.random.randint(-max_perturbation, max_perturbation + 1)\n",
    "            new_value = x[col] + perturbation\n",
    "\n",
    "            # Ensure the perturbed value is non-negative (not below 0)\n",
    "            x_prime[col] = max(0, new_value)\n",
    "\n",
    "        neighborhood.append(x_prime.values)\n",
    "\n",
    "    return np.array(neighborhood)\n",
    "\n",
    "def sample_neighborhood(x: np.ndarray, nn: NearestNeighbors, dataset: pd.DataFrame, k=10):\n",
    "    _, indices = nn.kneighbors(x, n_neighbors=k)\n",
    "    neigh_idcs = indices[0][1:]\n",
    "    neigh_vals = dataset.iloc[neigh_idcs].values\n",
    "    return neigh_vals\n",
    "\n",
    "\n",
    "def calculate_stability(model, explainer, dataset, k_neighbors=10, thresh=0.95, num_samples=1, debug=False, neigh=\"gen\", sim=\"jaccard\", norm=False):\n",
    "    assert neigh in [\"gen\",\"sampled\"]\n",
    "    assert sim in [\"jaccard\",\"hamming\"]\n",
    "\n",
    "    stability_scores = []\n",
    "    if neigh == \"sampled\":\n",
    "        nn = NearestNeighbors(n_neighbors=k_neighbors + 1).fit(dataset.values)\n",
    "\n",
    "    if norm:\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit_transform(dataset.values)\n",
    "\n",
    "    for i in tqdm(range(num_samples), desc=\"Calculating stability...\"):\n",
    "        x = dataset.iloc[i]\n",
    "        x_val = x.values.reshape(1, -1)\n",
    "        if debug:\n",
    "            print(\"Row:\\t\", list(x.values))\n",
    "\n",
    "        try:\n",
    "            anchor_x = explainer.explain_instance(x_val[0], classifier_fn=model.predict, threshold=thresh)\n",
    "            rule_x = set(anchor_x.names())\n",
    "            if not rule_x:\n",
    "                if debug:\n",
    "                    print(f\"No rule on index {i}. Skipping instance...\")\n",
    "                continue  # Skip if no rule was found\n",
    "            if debug:\n",
    "                print(\"Exp:\\t\", anchor_x.names())\n",
    "        except:\n",
    "            if debug:\n",
    "                print(f\"Anchor failed on index {i}. Skipping instance...\")\n",
    "            continue  # Skip instances where anchor fails\n",
    "\n",
    "        # Find neighbors (excluding self)\n",
    "        if neigh == \"gen\":\n",
    "            neigh_vals = generate_perturbation_neighborhood(x, dataset, num_samples=k_neighbors)\n",
    "        else:\n",
    "            neigh_vals = sample_neighborhood(x_val, nn, dataset)\n",
    "\n",
    "        lipschitz_vals = []\n",
    "        for j, x_prime in enumerate(neigh_vals):\n",
    "            if debug:\n",
    "                print(f\"\\n\\tNN{j}:\\t\", list(x_prime))\n",
    "            #try:\n",
    "            anchor_xp = explainer.explain_instance(x_prime.reshape(1, -1), classifier_fn=model.predict, threshold=thresh)\n",
    "            if debug:\n",
    "                print(\"\\tExp:\\t\", anchor_xp.names())\n",
    "            \n",
    "            rule_xp = set(anchor_xp.names())\n",
    "\n",
    "            lip = calc_lipschitz(\n",
    "                exp_x=rule_x,\n",
    "                exp_xp=rule_xp,\n",
    "                x=x.values,\n",
    "                xp=x_prime,\n",
    "                debug=debug,\n",
    "                sim=sim,\n",
    "                scaler=scaler if norm else None\n",
    "            )\n",
    "            lipschitz_vals.append(lip)\n",
    "            #except:\n",
    "                #print(f\"Error occured in neighbor explanation. Skipping instance.\")\n",
    "                #continue  # If explanation fails, skip\n",
    "\n",
    "        if lipschitz_vals:\n",
    "            max_lip = np.max(lipschitz_vals)\n",
    "            if debug:\n",
    "                print(\"\\nMax Lipstein:\\t\", max_lip)\n",
    "            stability_scores.append(max_lip)\n",
    "\n",
    "    return np.mean(stability_scores) if stability_scores else 0.0\n",
    "\n",
    "num_samples = 5\n",
    "debug = False\n",
    "neigh = \"sampled\" # \"sampled\" | \"gen\"\n",
    "sim = \"hamming\" # \"hamming\" | \"jaccard\"\n",
    "norm = True\n",
    "\n",
    "stabilities = []\n",
    "for model in [lg, xgb, cat]:\n",
    "    stability = calculate_stability(\n",
    "        xgb, explainer, test_set, \n",
    "        num_samples=num_samples,\n",
    "        debug=debug,\n",
    "        neigh=neigh,\n",
    "        sim=sim,\n",
    "        norm=norm\n",
    "    )\n",
    "    stabilities.append(stability)\n",
    "\n",
    "print(\"LG Stability:\", stabilities[0])\n",
    "print(\"XGB Stability:\", stabilities[1])\n",
    "print(\"CAT Stability:\", stabilities[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c3777",
   "metadata": {},
   "source": [
    "## Brute Force Paper Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e393eac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Preprocessing: l1 ==\n",
      "  -- Distance: euclidean\n",
      "    >> Model: lg\n",
      "      || Exp-diff: jaccard\n",
      "      Lip: 396.56337559385486\n",
      "      Err: 295.49337559385486\n",
      "      || Exp-diff: hamming\n",
      "      Lip: 621.249287074608\n",
      "      Err: 520.179287074608\n",
      "  -- Distance: manhattan\n",
      "    >> Model: lg\n",
      "      || Exp-diff: jaccard\n",
      "      Lip: 130.98610743360933\n",
      "      Err: 29.91610743360934\n",
      "      || Exp-diff: hamming\n",
      "      Lip: 197.32956478084284\n",
      "      Err: 96.25956478084285\n",
      "  -- Distance: cosine\n",
      "    >> Model: lg\n",
      "      || Exp-diff: jaccard\n",
      "      Lip: 528298.719241725\n",
      "      Err: 528197.6492417251\n",
      "      || Exp-diff: hamming\n",
      "      Lip: 845995.4596325671\n",
      "      Err: 845894.3896325672\n",
      "== Preprocessing: l2 ==\n",
      "  -- Distance: euclidean\n",
      "    >> Model: lg\n",
      "      || Exp-diff: jaccard\n",
      "      Lip: 437.88487328755707\n",
      "      Err: 336.8148732875571\n",
      "      || Exp-diff: hamming\n",
      "      Lip: 721.0975801336272\n",
      "      Err: 620.0275801336272\n",
      "  -- Distance: manhattan\n",
      "    >> Model: lg\n",
      "      || Exp-diff: jaccard\n",
      "      Lip: 146.94376655081436\n",
      "      Err: 45.873766550814366\n",
      "      || Exp-diff: hamming\n",
      "      Lip: 241.93382555048765\n",
      "      Err: 140.86382555048766\n",
      "  -- Distance: cosine\n",
      "    >> Model: lg\n",
      "      || Exp-diff: jaccard\n",
      "      Lip: 524892.7673199859\n",
      "      Err: 524791.697319986\n",
      "      || Exp-diff: hamming\n",
      "      Lip: 934179.130147862\n",
      "      Err: 934078.0601478621\n",
      "== Preprocessing: zscore ==\n",
      "  -- Distance: euclidean\n",
      "    >> Model: lg\n",
      "      || Exp-diff: jaccard\n",
      "      Lip: 0.33966921257331867\n",
      "      Err: 100.73033078742668\n",
      "      || Exp-diff: hamming\n",
      "      Lip: 0.4868135098996052\n",
      "      Err: 100.58318649010039\n",
      "  -- Distance: manhattan\n",
      "    >> Model: lg\n",
      "      || Exp-diff: jaccard\n",
      "      Lip: 0.14044295664735076\n",
      "      Err: 100.92955704335264\n",
      "      || Exp-diff: hamming\n",
      "      Lip: 0.22952380508261278\n",
      "      Err: 100.84047619491739\n",
      "  -- Distance: cosine\n",
      "    >> Model: lg\n",
      "      || Exp-diff: jaccard\n",
      "      Lip: 3.5226270105149418\n",
      "      Err: 97.54737298948505\n",
      "      || Exp-diff: hamming\n",
      "      Lip: 5.30934232999549\n",
      "      Err: 95.7606576700045\n",
      "== Preprocessing: minmax ==\n",
      "  -- Distance: euclidean\n",
      "    >> Model: lg\n",
      "      || Exp-diff: jaccard\n",
      "      Lip: 1.2222658363958192\n",
      "      Err: 99.84773416360417\n",
      "      || Exp-diff: hamming\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1407109/1866524992.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                         x_prime_anchor = explainer.explain_instance(\n\u001b[0;32m--> 133\u001b[0;31m                             \u001b[0mx_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                         )\n\u001b[1;32m    135\u001b[0m                         \u001b[0mrule_xp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_prime_anchor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/code/XAI-Survey/.venv/lib/python3.7/site-packages/anchor/anchor_tabular.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, data_row, classifier_fn, threshold, delta, tau, batch_size, max_anchor_size, desired_label, beam_size, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0msample_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mdesired_confidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_anchor_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_anchor_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_names_to_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instance'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/code/XAI-Survey/.venv/lib/python3.7/site-packages/anchor/anchor_base.py\u001b[0m in \u001b[0;36manchor_beam\u001b[0;34m(sample_fn, delta, epsilon, batch_size, min_shared_samples, desired_confidence, beam_size, verbose, epsilon_stop, min_samples_start, max_anchor_size, verbose_every, stop_on_first, coverage_samples)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0msample_fns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 verbose=verbose, verbose_every=verbose_every)\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0mbest_of_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchosen_tuples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/code/XAI-Survey/.venv/lib/python3.7/site-packages/anchor/anchor_base.py\u001b[0m in \u001b[0;36mlucb\u001b[0;34m(sample_fns, initial_stats, epsilon, delta, batch_size, top_n, verbose, verbose_every)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositives\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mut\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0msorted_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/code/XAI-Survey/.venv/lib/python3.7/site-packages/anchor/anchor_base.py\u001b[0m in \u001b[0;36mupdate_bounds\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnot_J\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 ub[f] = AnchorBaseBeam.dup_bernoulli(means[f], beta /\n\u001b[0;32m---> 85\u001b[0;31m                                                      n_samples[f])\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 lb[f] = AnchorBaseBeam.dlow_bernoulli(means[f],\n",
      "\u001b[0;32m~/dev/code/XAI-Survey/.venv/lib/python3.7/site-packages/anchor/anchor_base.py\u001b[0m in \u001b[0;36mdup_bernoulli\u001b[0;34m(p, level)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mqm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m#         print 'lm', lm, 'qm', qm, kl_bernoulli(p, qm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mAnchorBaseBeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl_bernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/code/XAI-Survey/.venv/lib/python3.7/site-packages/anchor/anchor_base.py\u001b[0m in \u001b[0;36mkl_bernoulli\u001b[0;34m(p, q)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9999999999999999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0000001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return (p * np.log(float(p) / q) + (1 - p) *\n\u001b[0;32m---> 26\u001b[0;31m                 np.log(float(1 - p) / (1 - q)))\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    Normalizer,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler,\n",
    "    QuantileTransformer,\n",
    ")\n",
    "\n",
    "\n",
    "preprocessing = {\n",
    "    #\"raw\": lambda x: x,\n",
    "    \"l1\": Normalizer(norm='l1'),\n",
    "    #\"l2\": Normalizer(norm='l2'),\n",
    "    #\"zscore\": StandardScaler(),\n",
    "    #\"minmax\": MinMaxScaler(),\n",
    "    #\"robust\": RobustScaler(),\n",
    "    #\"quantile_normal\": QuantileTransformer(output_distribution='normal'),\n",
    "    #\"quantile_uniform\": QuantileTransformer(output_distribution='uniform'),\n",
    "}\n",
    "distance_metrics = {\n",
    "    #\"euclidean\": lambda x1, x2: np.linalg.norm(x1 - x2, ord=2),\n",
    "    \"manhattan\": lambda x1, x2: np.linalg.norm(x1 - x2, ord=1),\n",
    "    #\"cosine\": lambda x1, x2: distance.cosine(x1, x2),\n",
    "}\n",
    "expl_differences = {\n",
    "    \"jaccard\": lambda exp1, exp2: jaccard_distance(exp1, exp2),\n",
    "    #\"hamming\": lambda exp1, exp2: hamming_distance(exp1, exp2),\n",
    "}\n",
    "model_fns = {\n",
    "    \"lg\": lg.predict,\n",
    "    \"xgb\": xgb_fn,\n",
    "    \"cat\": cat.predict,\n",
    "}\n",
    "paper = {\n",
    "    \"means\": {\n",
    "        \"lg\": 101.07,\n",
    "        \"xgb\": 121.40,\n",
    "        \"cat\": 123.79,\n",
    "    },\n",
    "    \"std\": {\n",
    "        \"lg\": 62.75,\n",
    "        \"xgb\": 98.43,\n",
    "        \"cat\": 76.86,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "num_samples = 10\n",
    "k_neighbors = 10\n",
    "thresh = 0.95\n",
    "\n",
    "\n",
    "def jaccard_distance(exp_x: set, exp_x_neigh: set, debug=False):\n",
    "    \"\"\"Distance between two explanations.\"\"\"\n",
    "    union = exp_x | exp_x_neigh\n",
    "    if not union:\n",
    "        return 0.0  # If both are empty, treat as identical\n",
    "    jacc = 1 - len(exp_x & exp_x_neigh) / len(union)\n",
    "    if debug:\n",
    "        print(\"\\tJacc:\\t\", jacc)\n",
    "    return jacc\n",
    "\n",
    "def hamming_distance(exp_x: set, exp_x_neigh: set, debug=False):\n",
    "    \"\"\"Distance between two explanations using Hamming distance.\"\"\"\n",
    "    # Calculate the symmetric difference between the two sets\n",
    "    diff = exp_x ^ exp_x_neigh  # ^ is symmetric difference\n",
    "    # Normalize the distance by the maximum possible number of differences (size of the union)\n",
    "    max_diff = max(len(exp_x), len(exp_x_neigh))\n",
    "    if max_diff == 0:\n",
    "        return 0.0  # If both are empty, treat as identical\n",
    "    \n",
    "    hamming = len(diff) / max_diff\n",
    "    \n",
    "    if debug:\n",
    "        print(\"\\tHamming:\\t\", hamming)\n",
    "    \n",
    "    return hamming\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=k_neighbors + 1).fit(test_set.values)\n",
    "def neighbors_of(x: np.ndarray):\n",
    "    _, indices = nn.kneighbors(x, n_neighbors=k_neighbors)\n",
    "    neigh_idcs = indices[0][1:]\n",
    "    neigh_vals = test_set.iloc[neigh_idcs].values\n",
    "    return neigh_vals\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sample_indices = np.random.choice(len(test_set), size=num_samples, replace=False)\n",
    "stability_results = []\n",
    "\n",
    "for pre_name, pre in preprocessing.items():\n",
    "    print(f\"== Preprocessing: {pre_name} ==\")\n",
    "\n",
    "    # Fit-transform\n",
    "    if callable(pre):  # for \"raw\"\n",
    "        X_prep = pre(test_set.values)\n",
    "    else:\n",
    "        X_prep = pre.fit_transform(test_set.values)\n",
    "\n",
    "    for dist_name, dist_fn in distance_metrics.items():\n",
    "        print(f\"  -- Distance: {dist_name}\")\n",
    "\n",
    "        nn = NearestNeighbors(n_neighbors=k_neighbors + 1, metric=\"euclidean\")\n",
    "        nn.fit(X_prep)\n",
    "\n",
    "        for model_name, model_fn in model_fns.items():\n",
    "            print(f\"    >> Model: {model_name}\")\n",
    "\n",
    "            for expl_name, expl_diff_fn in expl_differences.items():\n",
    "                print(f\"      || Exp-diff: {expl_name}\")\n",
    "\n",
    "                L_x = []\n",
    "                for i in sample_indices:\n",
    "                    x = test_set.values[i]\n",
    "                    x_prep = X_prep[i].reshape(1, -1)\n",
    "                    _, indices = nn.kneighbors(x_prep)\n",
    "                    neigh_idcs = indices[0][1:]\n",
    "                    \n",
    "                    x_anchor = explainer.explain_instance(\n",
    "                        x, classifier_fn=model_fn, threshold=thresh\n",
    "                    )\n",
    "                    rule_x = set(x_anchor.names())\n",
    "\n",
    "                    lips = []\n",
    "                    for j in neigh_idcs:\n",
    "                        x_prime = test_set.values[j]\n",
    "                        x_prime_prep = X_prep[j]\n",
    "\n",
    "                        x_prime_anchor = explainer.explain_instance(\n",
    "                            x_prime, classifier_fn=model_fn, threshold=thresh\n",
    "                        )\n",
    "                        rule_xp = set(x_prime_anchor.names())\n",
    "\n",
    "                        # Explanation distance\n",
    "                        expl_diff = expl_diff_fn(rule_x, rule_xp)\n",
    "\n",
    "                        # Input distance\n",
    "                        input_dist = dist_fn(X_prep[i], x_prime_prep)\n",
    "                        if input_dist == 0:\n",
    "                            print(\"Input distance == 0, skipping...\")\n",
    "                            continue  # skip duplicates or same point\n",
    "\n",
    "                        lip = expl_diff / input_dist\n",
    "                        lips.append(lip)\n",
    "                    \n",
    "                    L_x.append(max(lips))\n",
    "\n",
    "                if L_x:\n",
    "                    stability_results.append({\n",
    "                        \"preprocessing\": pre_name,\n",
    "                        \"distance\": dist_name,\n",
    "                        \"model\": model_name,\n",
    "                        \"lipschitz_vals\": L_x,\n",
    "                        \"liptschitz_mean\": np.mean(L_x),\n",
    "                    })\n",
    "                print(\"      Lip:\", np.mean(L_x))\n",
    "                print(\"      Err:\", abs(np.mean(L_x) - paper[\"means\"][model_name]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-survey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
